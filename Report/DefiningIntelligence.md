Defining what makes something intelligent has been an issue for a long time.  The Turing Test was created to determine if something is intelligent, but it doesn't help to determine if the implementation of the Artificial Intelligence is on the right track.  A machine may come close to passing the test, but how the machine works may be completely wrong and have no possibility of ever passing the test.  It is not scalable into intelligence.  The test can just tell the programmer what needs to be fixed or added.  This causes an issue with the progress of development for Artificial Intelligence.  Instead of focusing on developing a program that becomes more intelligent by adding more processing power, the test caused programmers to only focus on creating something intelligent piece by piece.  This has caused an interesting imbalance with technology.  There are advance machines that can understand spoken language but there is yet to be a machine that can walk with the same ease as the most basic animal.  By building a program that becomes more intelligent by adding more processing power, the program becomes smarter by following Moors Law.  

The reason this has happened is because of how programers have looked at what makes something intelligent.  The most common belief is that if something behaves intelligent, then it is intelligent.  Programmers focus on building applications that analyze human input and output a response that seems like something a human might respond with.  The program is not aware of either itself nor the world around it, because the system is entirely all scripted.  This is like reading a list of directions for every response in any context; unable to make any decisions because it does not know anything.  Saying a machine behaves intelligent is the same as saying that it is perceived to be intelligent, that is, the output of the machine is intelligent in context to the input to the machine.  A list of responses to input is one version of how a machine can act intelligent.  There can be many more that accounts for the different fields of Artificial Intelligence, like Neural Networks or Expert Systems.  All of these are solely focused on creating intelligent behavior and not creating something intelligent.  To do that, a programmer must solve what makes something act intelligent.  

One such programmer has done that, Jeff Hawkins of Numenta.  Hawkins has spent years trying to crack the case of what makes something intelligent.  He decided the best method was to look at something that is already intelligent.  By studying the inner workings of the human brain, he has finally cracked the case.  Prediction.  

Prediction allows humans to learn and to detect when something is wrong.  A machine may stumble upon doing that is desired.  The machine can then predict that if it does the same actions before, its outcome will be the same; it learns.  If something happens to a machine that is unpredicted, it knows instantly.  It does not need to go through a series of checks to determine if some value is off because the system is predicting in every single state.  Prediction is the lowest level action going on in the brain and can be expanded much like how emotions work; something is either positive or negative and by adding more and more complexity, different types of emotions are created that have different effects on the body.  In the same way, a prediction can be either true or false and by adding more and more complexity, a brain can learn, detect, and control what it does.  Hawkins calls this complexity, the Hierarchal Temporal Memory Theory and it is based entirely on how the brain is structured and functions.  This is how it works.
