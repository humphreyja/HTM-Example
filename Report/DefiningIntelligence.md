Defining what makes something intelligent has been an issue for a long time.  The Turing Test was created to determine if something is intelligent, but it doesn't help to determine if the implementation of the Artificial Intelligence is on the right track.  A machine may come close to passing the test, but how the machine works may be completely wrong and have no possibility of ever passing the test.  It is not scalable into intelligence.  The test can just tell the programmer what needs to be fixed or added.  This causes an issue with the progress of development for Artificial Intelligence.  Instead of focusing on developing a program that becomes more intelligent by adding more processing power, the test caused programmers to only focus on creating something intelligent piece by piece.  This has caused an interesting imbalance with technology.  There are advance machines that can understand spoken language but there is yet to be a machine that can walk with the same ease as the most basic animal.  By building a program that becomes more intelligent by adding more processing power, the program becomes smarter by following Moors Law.  

The reason this has happened is because of how programers have looked at what makes something intelligent.  The most common belief is that if something behaves intelligent, then it is intelligent.  Programmers focus on building applications that analyze human input and output a response that seems like something a human might respond with.  The program is not aware of either itself nor the world around it, because the system is entirely all scripted.  This is like reading a list of directions for every response in any context; unable to make any decisions because it does not know anything.  Saying a machine behaves intelligent is the same as saying that it is perceived to be intelligent, that is, the output of the machine is intelligent in context to the input to the machine.  A list of responses to input is one version of how a machine can act intelligent.  There can be many more that accounts for the different fields of Artificial Intelligence, like Neural Networks or Expert Systems.  All of these are solely focused on creating intelligent behavior and not creating something intelligent.  To do that, a programmer must solve what makes something act intelligent.  

One such programmer has done that, Jeff Hawkins of Numenta.  Hawkins has spent years trying to crack the case of what makes something intelligent.  He decided the best method was to look at something that is already intelligent.  By studying the inner workings of the human brain, he has finally cracked the case.  Prediction.  

Prediction allows humans to learn and to detect when something is wrong.  A machine may stumble upon doing that is desired.  The machine can then predict that if it does the same actions before, its outcome will be the same; it learns.  If something happens to a machine that is unpredicted, it knows instantly.  It does not need to go through a series of checks to determine if some value is off because the system is predicting in every single state.  Prediction is the lowest level action going on in the brain and can be expanded much like how emotions work; something is either positive or negative and by adding more and more complexity, different types of emotions are created that have different effects on the body.  In the same way, a prediction can be either true or false and by adding more and more complexity, a brain can learn, detect, and control what it does.  Hawkins calls this complexity the Hierarchal Temporal Memory Theory and it is based entirely on how the brain is structured and functions.  This is how it works.

The Neocortex exists only in mammals.  It is the most recent addition to the development of the brain.  In more primitive animals, like the mouse, the Neocortex is smooth.  In humans however, the Neocortex is wrinkled.  This is because of human brains are much more developed than say a mouse brain.  A mouse's Neocortex is only about the size of a postage stamp, where the human Neocortex is about the size of a 24 by 24 inch dinner napkin.  In order for more of the Neocortex to fit into the human skull, it developed ridges and valleys to allow for more surface area which in turn makes it much larger.  This also provides humans with a far superior brain than a mouse brain.  The Neocortex is also made up of several regions that are both specialized and generalized regions.  A specialized region may be the V1 region in the Visual Cortex that is only in charge of processing visual input.  Other regions accept input from many different sources.  Each region is also highly connected to the regions around it and are organized in a connected hierarchy of regions.  The topmost region of the hierarchy is the Hippocampus.  Inside each region of the Neocortex, there are six layers.  The first layer is often disregarded as it does not contain any neurons in it.  Layers 2 and 3 are also combined into the layer 2/3 as they function the same and have the same cellular constructs.  Each layer also has many mini-columns.  These columns are still under question in biology though Jeff Hawkins has found enough proof to accept these into the HTM Theory as they are paramount to how the theory works.  This structure is repeated across the entire Neocortex, there is no change aside from different sizes of the layers in different regions.  This is to provide that region with better or worse input.  A bat brain, for example, has a much larger layer 4 in its Auditory Cortex region and has almost a nonexistent layer 4 in its Visual Cortex region.  This allows bats to have incredible hearing but have very poor eyesight.  Finally, there are neurons.  These are cells that have three different states, primed, firing, dormant.  A neuron may be triggered by a certain set of sections of an inputted pattern based on what their proximal dendrites connect to.  The distal dendrites form connections to other cells in the region and if enough of those cells fire, then they will set the cell into a primed state.  This primed state causes the cell to fire much more easily and much stronger than the cells around it.  It also causes another kind of cell in layer 2/3 called inhibitory cells to stop the other surrounding cells in that area from firing.    

Each layer has a function as well.  Layer 2/3 is the inference/prediction layer; it is what forms input based memories like seeing a familiar object or hearing a familiar sound.  Layer 4 forms simple motor functions that seek input.  An example of this is the saccade movements that human eyes do about three times every second.  These are unknown to the person as the brain patches it all together into a single image.  The movements follow a common path when viewing objects like a human face.  They will often first look at the eyes, then the nose, then the mouth; they are looking at the facial features of the person.  This input is then passed up to the layer 2/3 for processing.  Next, layer 5 handles complex motor movement.  This is the muscle memory that is used everywhere in the body.  It is used to speak, walk, or any activity that requires even the smallest movement.  There is no database of words or grammar rules built into the brain; it is simply memories of how to move the mouth and vocal cords to form the sound of the words.  Lastly, layer 6 is used for attention.  Jeff Hawkins has yet to focus very much time into this layer and the previous so this report will not reference them.  

Memories are built based on input and feedback through the hierarchy structure.  As said before, the entire brain works off of prediction.  When the brain successfully predicts a pattern in its input, it builds the relationships involved in that prediction.  When input is received from the body, it enters the lowest regions of the brain.  If that region does not predict that input, it passes the input to the next higher region to see if that region can predict the pattern.  As the input gets passed further and further up the hierarchy, the prediction becomes more and more generalized; it is much more likely to predict the input near the very top of the hierarchy.  Once the input is predicted, the region builds the relationships involved in that region as well as passes feedback back down the hierarchy to tell the rest of the regions involved about the successful prediction.  The input also does not need to be predicted entirely in one region.  Part of the input is predicted in all of the regions involved and overtime, the lower regions slowly start to form predictions to the rest of the input.  This allows for input to become predicted lower and lower in the hierarchy of the brain effectively freeing up the topmost regions of the Neocortex for more complex thinking and multitasking.  In other words, the memories become muscle memory.  If the inputted pattern is a first occurrence, like seeing someone in a new context or location, or having a specific conversation, the input reaches the top most region, the Hippocampus.  The patterns that reach this region are new memories.  This is shown in victims that have suffered damage to their Hippocampus and are unable to form new memories.  

The mini-columns of the Neocortex are very important to learning memories.  The following example will work through how exactly the brain can learn to predict two similar patterns and still tell the difference between the two.  Pattern 1 will be A-B-C-D, pattern 2 will be X-B-C-Y.  The problem will be to predict the last letter in the sequence.  When an input is first received, if a cell has formed any relationships with any of the input from that pattern, it will try to fire.  If the cell is not primed, it will cause every cell in the column to fire.  If more of the input matches the cell, then the column will have a stronger fire and will try to inhibit the rest of the columns around it.  The result is that the entire layers output will only have about 2% of the columns firing.  Then, then next input is received and goes through the same process.  The previous input is passed to the Thalamus, which acts much like the clock of a computer, and is passed back to the layer in the form of feedback.  The layer now has the new input as well as a record of the previous input.  The cells that fire in the new input build relationships with all of the cells that fired in the previous state.  This allows for the brain to form First Order sequence memories.  This would be predicting patterns like: A-B, A-C, A-D, etc.  If it sees the input A, it cannot tell if the next input will be either B, C, or D, it can just predict that the next input will be one of those three.  To form Higher Order Sequence memories, the mini-columns need to be taken into account.  There are many cells in the column.  When the first input is received, it is not predicted and the entire column fires.  The layer then predicts the next pattern, using the two patterns declared earlier, the first input could be either A or X and both patterns cause B to be predicted.  When B fires, it forms relationships with either A or X.  The difference here is that, when A is received, only a single cell in the columns for B becomes primed.  When the B input is received, only that single cell fires, not the entire column.  The single cells are different for A and X predictions.  The output after the B input is received is completely different for each of the two patterns.  This can then predict the rest of the pattern.  

In order to program this, Sparse Data Representation(SDR) is used.  The contrary of this is Dense Data Representation which is used for almost all data types in programming.  An example of this is ASCII letters.  A letter is mapped to a number which is just an index in a table.  The number does not provide any meaning to the letter. Adding the index numbers for M and N does not give you the meaning Minnesota for example.  Sparse Data Representation does provide meaning in its binary representation.  Each bit is an attribute and by adding two SDRs, a meaning is formed for the combination of those two variables.  It requires to be sparse, so only about 2% of the variables bits are active, or set to 1, the rest are 0.  To be effective these SDRs need to be hundreds to thousands of bits long.  To reserve space, only the active bits are stored as a set.  Set logic can then be applied which allows for many more useful actions.  For example, adding several SDR sets together can result in a master set with about 20% bit active.  While there is no way to reverse where the attributes originated from, generalization can be done by checking if a set is a subset of the master set.  Also, comparing the amount of similar attributes of two sets determines how semantically similar the two objects are.  Hardware restrictions may also be an issue when using these data types.  This can be overcome by taking a subsample of a set.  The effects of this are a greater chance of an error to be made, but the error would be made with an object that is semantically similar, though the chances of this are not very likely.  

SDRs are used to represent the input pattern to a layer.  Each cells proximal dendrites form a single set that is several patterns added together into a general set with about 20% of the bits active.  The distal dendrites are a scalar value between 0 and 1.  When a cell is forming a relationship with another cell, the value is incremented.  Once this value is over 0.4, the connection is made.  This allows for the relationship to continue to build stronger and stronger, and allows for the relationship to take much longer to forget.  This can be stored as just the strength of the connection and the pattern that was inputted during that state.  Anytime the cell sees that pattern, it will be put into the primed state as it is predicting that it will fire the next time.  A cell can also predict incorrectly, when it does, the relationship is decremented.  This also occurs when the relationship is not used for a long time and the relationship starts to decay.  Lastly, if a cell has not fired in a long time, it becomes more and more likely to fire.  It will change the proximal dendrite pattern to allow itself to fire more often.  This causes cells to fight to fire and none of them will be underused.  

That concludes Jeff Hawkins HTM Theory.  The entire theory is built using biological constraints, that is, Jeff Hawkins will not add a feature into the theory unless it is first proven with significant evidence that it exists in the biological brain.  
